#!/usr/bin/env python3
# -*- coding: utf-8 -*-

' 爬虫 '

_author_='挖数'

#作者：挖数
#链接：https://www.zhihu.com/question/20899988/answer/96904827
#来源：知乎
#著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

import requests
import urllib
import re
import random
from time import sleep
def main():
    url='https://www.zhihu.com/question/22591304/followers'
    #感觉这个话题下面美女多
    headers={'省略'}
    i=1
    for x in range(20,3600,20):
        data={'start':'0','offset':str(x),'_xsrf':'a128464ef225a69348cef94c38f4e428'}
        #知乎用offset控制加载的个数，每次响应加载20
        content=requests.post(url,headers=headers,data=data,timeout=10).text
        #用post提交form data
        imgs=re.findall('<img src=\\\\\"(.*?)_m.jpg',content) 
        #在爬下来的json上用正则提取图片地址，去掉_m为大图 
        for img in imgs:
            try:
                img=img.replace('\\','')
                #去掉\字符这个干扰成分
                pic=img+'.jpg'
                path='d:\\bs4\\zhihu\\jpg\\'+str(i)+'.jpg'
                #声明存储地址及图片名称
                urllib.urlretrieve(pic,path)
                #下载图片
                print('下载了第'+str(i)+'张图片')
                i+=1
                sleep(random.uniform(0.5,1))#睡眠函数用于防止爬取过快被封IP
            except:
                print('抓漏1张')
                pass
                sleep(random.uniform(0.5,1))

if __name__=='__main__':
    main()
